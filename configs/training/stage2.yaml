data:
  target: gem.data.curated_dataset.CuratedSampler 
  params:
    data_dict:
      - depth_img
      - trajectory
      - rendered_poses
    total_anno_file: annotations_full.csv
    batch_size: 1  #3 
    num_workers: 32 
    target_height: &target_height 576 #320 
    target_width: &target_width 1024 #576 
    num_frames: &num_frames 25
    step_size: 25 #15
    # enable_skeletons: true
    filter: True
    # quality filtering
    aesthetic_threshold: 3.8
    piqe_threshold: 80 
    blur_threshold: 10000

    # content filtering
    diversity_setting: in_similarity_95 #in_similarity_98 # 98, 95, 90, 85, 75
    sscd_setting: 
    patch_similarity_50: 0.02
    motion_score_threshold: 0 #0.05
    environment_score_threshold: [0, 0, 0, 0]  
    reference_frame_horizon: 0 #1000

lightning:
  logger:
    target: pytorch_lightning.loggers.WandbLogger
    params:
      project: "gem_stage2"
      id:   # Optional, to resume a run

  callbacks:
    image_logger:
      target: train.ImageLogger
      params:
        num_frames: *num_frames
        disabled: False
        enable_autocast: False
        batch_frequency: 200
        increase_log_steps: False
        log_first_step: True 
        log_images_kwargs:
          N: *num_frames

  modelcheckpoint:
    params:
      every_n_train_steps: 300  # , set the same as image_logger batch_frequency

  trainer:
    devices: 4
    benchmark: True
    log_every_n_steps: 10
    num_nodes: 1
    num_sanity_val_steps: 0
    accumulate_grad_batches: 1
    max_epochs: 100
    strategy: deepspeed_stage_2_offload  #ddp_find_unused_parameters_true #deepspeed_stage_2 
    gradient_clip_val: 0.3

model:
  base_learning_rate: 3e-5 
  target: gem.models.diffusion.DiffusionEngine 
  params:
    optimizer_config:
      target: deepspeed.ops.adam.DeepSpeedCPUAdam
    use_ema: True
    input_key: img_seq
    scale_factor: &scale_factor 0.18215
    disable_first_stage_autocast: True
    en_and_decode_n_samples_a_time: 1
    num_frames: *num_frames  
    slow_spatial_layers: False 
    train_peft_adapters: False
    high_fd_control: False 
    slow_temporal_layers: False 
    replace_cond_frames: &replace_cond_frames False #True
    pixel_space_post_training: False 
    fixed_cond_frames: # only used for logging images
      - [ ]

    denoiser_config:
      target: gem.modules.diffusionmodules.denoiser.Denoiser
      params:
        num_frames: *num_frames

        scaling_config:
          target: gem.modules.diffusionmodules.denoiser_scaling.VScalingWithEDMcNoise

    network_config: 
      target:  gem.modules.diffusionmodules.video_model.VideoUNet
      params:
        adm_in_channels: 768
        num_classes: sequential
        use_checkpoint: True
        in_channels: 8
        out_channels: 4
        model_channels: &model_channels 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_head_channels: 64
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
        spatial_transformer_attn_type: softmax-xformers
        extra_ff_mix_layer: True
        use_spatial_context: True
        merge_strategy: learned_with_images
        video_kernel_size: [ 3, 1, 1 ]
        add_lora: False 
        action_control: True #False   

        dino_cnn_cfg:
          target: gem.modules.encoders.dino_cnn.DINOCNN
          params:
            num_classes: null
            use_checkpoint: true
            in_channels: 768 
            out_channels: [320, 640] 
            model_channels: 768 
            src_h_condition_idxs: [1, 3]
            dst_h_condition_idxs: [3, 6] 
            attention_resolutions: 
              - 1
              - 0
            num_res_blocks: 1
            channel_mult: 
              - 1
              - 1
            num_head_channels: 64
            use_linear_in_transformer: true
            transformer_depth: 1
            spatial_transformer_attn_type: softmax-xformers
            extra_ff_mix_layer: true
            merge_strategy: learned_with_images
            video_kernel_size: 
              - 3
              - 3
              - 3
            add_lora: false
            action_control: false
            disable_temporal_crossattention: true


    conditioner_config:
      target: gem.modules.GeneralConditioner
      params:
        emb_models:
          - input_key: cond_frames_without_noise
            is_trainable: False
            ucg_rate: 1.0 
            target: gem.modules.encoders.modules.DummyFrozenOpenCLIPImagePredictionEmbedder
            params:
              n_cond_frames: 1
              n_copies: 1
              open_clip_embedding_config:
                target: gem.modules.encoders.modules.FrozenOpenCLIPImageEmbedder
                params:
                  freeze: True

          - input_key: fps_id
            is_trainable: False
            ucg_rate: 0.0
            target: gem.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256

          - input_key: motion_bucket_id
            is_trainable: False
            ucg_rate: 0.0
            target: gem.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256

          - input_key: cond_frames
            is_trainable: False
            ucg_rate: 0.2
            target: gem.modules.encoders.modules.VideoPredictionEmbedderWithEncoder
            params:
              disable_encoder_autocast: True
              n_cond_frames: 1
              n_copies: 1
              is_ae: True

              encoder_config:
                target: gem.models.autoencoder.AutoencoderKLModeOnly
                params:
                  embed_dim: 4
                  monitor: val/rec_loss

                  ddconfig:
                    attn_type: vanilla-xformers
                    double_z: True
                    z_channels: 4
                    resolution: 256
                    in_channels: 3
                    out_ch: 3
                    ch: 128 
                    ch_mult: [ 1, 2, 4, 4 ]
                    num_res_blocks: 2
                    attn_resolutions: [ ]
                    dropout: 0.0

                  loss_config:
                    target: torch.nn.Identity

          - input_key: cond_aug
            is_trainable: False
            ucg_rate: 0.0
            target: gem.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256
            
          - input_key: img_seq
            is_trainable: True
            ucg_rate: 0.15
            target: gem.modules.encoders.dino_v2_features_id.DinoEncoder
            params:
              ucg_prob: 0.0 
              num_frames: *num_frames
              dino_version: dinov2_vitb14  #
              dino_channels: 768 
              proj_channels: 0 
              mode: 3d_id 
              learned_mask: False
              num_condition_tokens: 32 #32  # padded with mask if less tokens available
              image_height: *target_height 
              image_width: *target_width
              out_patch_size: 16
              #out_res: [20, 36] #[36, 64]  #[40, 72]  #[72, 128]
              num_random_condition_frames:  -1 #, for random number (between 0 and 10), 0 for fixed condition frames 
              condition_frames: [0, 5, 11, 18, 24] # is ignored
              num_dino_layers: 1
              mask_prob: 0.50 # is ignored in 3d
              random_crop_per_frame: True  # makes a random crop for each frame, otherwise the same for all frames in batch (width,height are equal for all frames)
              cage_crop: # width height nums should keep aspect ratio same
                min_w: 0.1  
                min_h: 0.2
                max_w: 0.6
                max_h: 0.8
              
          - input_key: trajectory
            is_trainable: False
            ucg_rate: 0.15
            target: gem.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 304
              num_features: 8
              add_sequence_dim: True
          
          - input_key: rendered_poses
            is_trainable: True
            ucg_rate: 0.2
            target: gem.modules.encoders.skeleton_encoder.SkeletonEncoder
            params:
              target_width: *target_width
              target_height: *target_height

    first_stage_config:
      target: gem.models.autoencoder.AutoencodingEngine
      params:
        loss_config:
          target: torch.nn.Identity

        regularizer_config:
          target: gem.modules.autoencoding.regularizers.DiagonalGaussianRegularizer

        encoder_config:
          target: gem.modules.diffusionmodules.model.Encoder
          params:
            attn_type: vanilla-xformers
            double_z: True
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128 
            ch_mult:  [ 1, 2, 4, 4 ] 
            num_res_blocks: 2
            attn_resolutions: [ ]
            dropout: 0.0

        decoder_config:
          target: gem.modules.autoencoding.temporal_ae.VideoDecoder
          params:
            attn_type: vanilla-xformers
            double_z: True
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128 
            ch_mult: [ 1, 2, 4, 4 ] 
            num_res_blocks: 2
            attn_resolutions: [ ]
            dropout: 0.0
            video_kernel_size: [ 3, 1, 1 ]

    scheduler_config:
      target: gem.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [ 500 ]
        cycle_lengths: [ 10000000000000 ]
        f_start: [ 1.e-6 ]
        f_max: [ 1. ]
        f_min: [ 1. ]

    loss_fn_config:
      target: gem.modules.diffusionmodules.loss.StandardDiffusionLossRe
      params:
        
        use_additional_loss: False 
        offset_noise_level: 0.02
        additional_loss_weight: 0.1
        num_frames: *num_frames
        replace_cond_frames: *replace_cond_frames
        custom_reference: False #True   
        cond_frames_choices: 
          - [ ]
 

        sigma_sampler_config:  
          target: gem.modules.diffusionmodules.sigma_sampling.CustomEDMSampling
          params:
            p_mean: 1.0 #0.7 #1.0
            p_std: 1.6
            num_frames: *num_frames
            sigma_max: &sigma_max 150 
            rho: 3.0 

        loss_weighting_config:
          target: gem.modules.diffusionmodules.loss_weighting.VWeighting
   

    sampler_config: 
      target: gem.modules.diffusionmodules.sampling.EulerEDMSamplerDynamicPyramid 
      params:
        num_steps: 50 #30 #30 #55  

        discretization_config:
          target: gem.modules.diffusionmodules.discretizer.EDMDiscretization
          params:
            sigma_max: 150  

        guider_config:   
          target: gem.modules.diffusionmodules.guiders.LinearPredictionGuider
          params:
            num_frames: *num_frames
            max_scale: 3.0
            min_scale: 1.5
